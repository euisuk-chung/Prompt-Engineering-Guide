# Phi-2

이 가이드에서는 27억 매개변수 언어 모델인 Phi-2, Phi-2를 프롬프팅하는 방법, 그리고 그 능력에 대한 개요를 제공합니다. 이 가이드는 또한 Phi-2 LLM과 관련된 팁, 응용 프로그램, 한계, 중요한 참고문헌, 추가 읽기 자료를 포함합니다.

## Phi-2 소개(Phi-2 Introduction)
Phi-2는 Microsoft Research가 출시한 최신 소형 언어 모델(SLM)입니다. Phi-2는 이전 Phi-1 모델과 Phi-1.5 모델을 따릅니다.

Phi-1은 웹의 "교과서 품질" 데이터(6B 토큰)와 GPT-3.5로 합성 생성된 교과서 및 연습문제(1B 토큰)([Gunasekar et al. 2023](https://arxiv.org/abs/2306.11644))로 훈련된 13억 매개변수 모델입니다. Python 코드 생성 작업에서 잘 수행됩니다.

[Phi-1.5](https://arxiv.org/abs/2309.05463)는 이전 모델을 기반으로 하며 상식 추론과 언어 이해 능력에 중점을 둡니다. Phi-1.5는 초등학교 수학과 기본 코딩 작업과 같은 복잡한 추론 작업을 수행할 수 있으며, 크기가 5배 큰 모델과 비교할 수 있습니다.

27억 매개변수 모델인 Phi-2는 추론과 언어 이해 능력을 향상시킵니다. Phi-2는 크기가 25배 큰 모델을 능가하며 이제 상업적 환경에서 사용할 수 있는 MIT 라이선스를 가지고 있습니다.

## Phi-2 통찰 및 평가(Phi-2 Insights & Evaluation)
LLM 연구자들은 소형 언어 모델이 대형 모델과 유사한 창발적 능력을 가지고 있는지, 그리고 이를 달성하는 데 도움이 될 수 있는 훈련 기법이 있는지 탐구하는 데 열정적입니다.

모델은 상식 추론과 일반 지식을 가르치는 데 도움이 되는 합성 데이터셋을 포함한 "교과서 품질" 데이터(다중 패스로 1.4조 토큰)로 훈련됩니다. 데이터는 교육적이고 고품질의 웹 콘텐츠로 증강됩니다. Phi-2는 96개의 A100 GPU에서 14일 동안 훈련되었습니다. 추가적인 RLHF나 지시사항 튜닝은 적용되지 않았습니다.

Phi-1.5 지식이 Phi-2로 전이되어 여러 벤치마크에서 모델 수렴과 성능 향상에 도움이 됩니다. 아래 그림은 상식 추론, 수학 추론, 코드 생성, 기타 언어 이해 벤치마크에서 Phi-2(2.7B)와 Phi-1.5(1.3B) 간의 성능 비교를 보여줍니다. BBH와 MMLU가 각각 3샷 CoT와 5샷을 사용한다는 점을 제외하고 모든 작업이 0샷으로 평가된다는 점에 주목하는 것이 중요합니다.

모델이 RLHF와 같은 특별한 기법으로 정렬되지 않았지만, 정렬된 오픈소스 Llama2-7b에 비해 독성과 편향 측면에서 더 안전하다고 보고됩니다. 저자들은 이를 데이터 큐레이션 노력에 기인합니다.

아래 그림에서 보듯이, Phi-2는 다양한 벤치마크에서 Mistral 7B와 Llama 2(13B)를 능가합니다. Phi-2는 다단계 추론에서 Llama-2-70B 모델도 능가합니다. Phi-2는 [Google의 Gemini Nano 2](https://www.promptingguide.ai/models/gemini)도 능가합니다.

아래에서는 Phi-2 모델의 여러 작업에서의 능력을 보여주는 여러 프롬프트 예시를 제공합니다.

### 물리 문제 해결(Physics Problem Solving)

아래 예시는 Phi-2가 물리 단어 문제를 해결하는 능력을 보여줍니다:

### 오류 식별(Error Identification)

아래 예시는 Phi-2가 물리 단어 문제에 대한 학생의 계산에서 실수를 식별하는 능력을 보여줍니다:

## Phi-2 사용법(Phi-2 Usage)
[모델 페이지](https://huggingface.co/microsoft/phi-2)에 따르면, Phi-2는 QA 형식, 채팅 형식, 코드 형식을 사용하여 프롬프팅할 수 있습니다. 아래에서는 다양한 시나리오를 사용하여 이러한 프롬프트 템플릿을 효과적으로 사용하는 방법을 보여줍니다.

### QA 형식(QA Format)
QA 형식은 모델에게 질문을 하고 간결한 답변을 원하는 시나리오에 유용합니다.

다음 프롬프트 템플릿을 사용할 수 있습니다:

```markdown
Instruct: {{prompt}}
Output:
```

예시는 다음과 같습니다:

*프롬프트:*
```
Instruct: 데이터와 정보의 차이점은 무엇인가요?
Output:
```

*출력:*
```
좋은 질문입니다! 데이터는 분석되거나 의미 있는 맥락으로 처리되지 않은 원시 사실, 통계 또는 숫자를 말합니다. 반면 정보는 인간이 정보에 입각한 결정을 내리거나 행동을 취할 수 있도록 조직화되고, 분석되고, 해석된 데이터입니다. 다시 말해, 데이터는 원료이고, 정보는 처리되고 유용한 지식입니다.
```

### 채팅 형식(Chat Format)
Phi-2가 사용하는 채팅 형식은 표준 형식이며 간단한 예시는 다음과 같습니다:

*프롬프트:*
```
Human: 안녕하세요, 당신은 누구인가요?
AI: 안녕하세요! 저는 AI 연구 어시스턴트입니다. 오늘 어떻게 도와드릴까요?
Human: 블랙홀의 생성에 대해 알려주실 수 있나요?
AI:
```

*출력:*
```
블랙홀은 거대한 별이 연료를 다 써버리고 자체 중력에 의해 붕괴될 때 형성됩니다. 결과물은 너무 밀도가 높아서 주변의 시공간을 왜곡시켜 너무 가까이 오는 모든 것을 엄청난 중력으로 끌어당깁니다. 여기에는 빠져나올 수 없는 빛도 포함됩니다...
```

### 코드 형식(Code Format)
아래는 모델에게 함수 이름을 제공하는 코드 생성 프롬프트 템플릿입니다:

*프롬프트:*
```
def multiply(a,b):\n
```

모델이 제한된 Python 코드 예시와 라이브러리로 훈련되었기 때문에 코드 생성 능력과 언어 지원이 상당히 제한적이라는 점을 기억하세요.

## Phi-2 한계(Phi-2 Limitations)
아래는 저자들이 보고한 Phi-2의 한계 요약입니다:

- 다른 모델과 유사하게, Phi-2는 부정확한 코드와 문장을 생성할 수 있습니다.
- Phi-2는 다른 모델처럼 지시사항 튜닝되지 않았으며 지시사항을 따르는 데 어려움을 겪을 수 있습니다.
- 훈련은 표준 영어로 구성되어 있으므로, 모델은 속어에 어려움을 겪고 다른 언어의 지시사항을 이해하지 못할 수 있습니다.
- Phi-2는 또한 사회적 편향과 독성 콘텐츠를 생성할 수 있습니다.
- Phi-2는 튜닝되지 않았고 장황한 응답을 생성하는 경향이 있으며, 때로는 관련 없는 추가 텍스트를 생성하기도 합니다. 저자들은 이것이 주로 교과서인 훈련 데이터셋의 특성 때문일 가능성이 높다고 제안합니다.

*그림 출처: [Microsoft Research](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/)*

## 참고문헌(References)
- [Textbooks Are All You Need](https://arxiv.org/abs/2306.11644)
- [Phi-1.5](https://arxiv.org/abs/2309.05463)